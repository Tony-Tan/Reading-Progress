<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.44.1 (20200629.0846)
 -->
<!-- Title: ML_Math Pages: 1 -->
<svg width="1928pt" height="241pt"
 viewBox="0.00 0.00 1928.00 241.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 237)">
<title>ML_Math</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-237 1924,-237 1924,4 -4,4"/>
<g id="clust3" class="cluster">
<title>cluster_dqn</title>
<polygon fill="none" stroke="black" stroke-dasharray="5,2" points="8,-8 8,-156 1912,-156 1912,-8 8,-8"/>
<text text-anchor="middle" x="960" y="-140.8" font-family="Times,serif" font-size="14.00">DQN</text>
</g>
<!-- a1993 -->
<g id="node1" class="node">
<title>a1993</title>
<polygon fill="none" stroke="black" points="1028,-233 644,-233 644,-197 1028,-197 1028,-233"/>
<text text-anchor="middle" x="836" y="-211.3" font-family="Times,serif" font-size="14.00">[1993] Reinforcement Learning for Robots Using Neural Networks</text>
</g>
<!-- a2013 -->
<g id="node2" class="node">
<title>a2013</title>
<polygon fill="none" stroke="black" points="999,-125 673,-125 673,-89 999,-89 999,-125"/>
<text text-anchor="middle" x="836" y="-103.3" font-family="Times,serif" font-size="14.00">[2013] Playing Atari with Deep Reinforcement Learning</text>
</g>
<!-- a1993&#45;&gt;a2013 -->
<g id="edge1" class="edge">
<title>a1993&#45;&gt;a2013</title>
<path fill="none" stroke="darkgreen" stroke-dasharray="5,2" d="M836,-196.97C836,-180.38 836,-154.88 836,-135.43"/>
<polygon fill="darkgreen" stroke="darkgreen" points="839.5,-135.34 836,-125.34 832.5,-135.34 839.5,-135.34"/>
<text text-anchor="middle" x="917.5" y="-167.8" font-family="Times,serif" font-size="14.00">experience replay mechanism</text>
</g>
<!-- a2015 -->
<g id="node3" class="node">
<title>a2015</title>
<polygon fill="none" stroke="black" points="372,-52 16,-52 16,-16 372,-16 372,-52"/>
<text text-anchor="middle" x="194" y="-30.3" font-family="Times,serif" font-size="14.00">[2015] Deep Reinforcement Learning with Double Q&#45;learning</text>
</g>
<!-- a2013&#45;&gt;a2015 -->
<g id="edge2" class="edge">
<title>a2013&#45;&gt;a2015</title>
<path fill="none" stroke="darkgreen" stroke-dasharray="5,2" d="M682.23,-88.99C584.41,-78.18 457.84,-64.18 358.09,-53.15"/>
<polygon fill="darkgreen" stroke="darkgreen" points="358.23,-49.64 347.91,-52.02 357.46,-56.6 358.23,-49.64"/>
</g>
<!-- a2016 -->
<g id="node4" class="node">
<title>a2016</title>
<polygon fill="none" stroke="black" points="610,-52 390,-52 390,-16 610,-16 610,-52"/>
<text text-anchor="middle" x="500" y="-30.3" font-family="Times,serif" font-size="14.00">[2016] Prioritized Experience Replay</text>
</g>
<!-- a2013&#45;&gt;a2016 -->
<g id="edge3" class="edge">
<title>a2013&#45;&gt;a2016</title>
<path fill="none" stroke="darkgreen" stroke-dasharray="5,2" d="M755.52,-88.99C705.82,-78.49 641.94,-64.99 590.48,-54.12"/>
<polygon fill="darkgreen" stroke="darkgreen" points="591.2,-50.7 580.7,-52.05 589.76,-57.54 591.2,-50.7"/>
</g>
<!-- b2016 -->
<g id="node5" class="node">
<title>b2016</title>
<polygon fill="none" stroke="black" points="1044,-52 628,-52 628,-16 1044,-16 1044,-52"/>
<text text-anchor="middle" x="836" y="-30.3" font-family="Times,serif" font-size="14.00">[2016] Dueling Network Architectures for Deep Reinforcement Learning</text>
</g>
<!-- a2013&#45;&gt;b2016 -->
<g id="edge4" class="edge">
<title>a2013&#45;&gt;b2016</title>
<path fill="none" stroke="darkgreen" stroke-dasharray="5,2" d="M836,-88.81C836,-80.79 836,-71.05 836,-62.07"/>
<polygon fill="darkgreen" stroke="darkgreen" points="839.5,-62.03 836,-52.03 832.5,-62.03 839.5,-62.03"/>
</g>
<!-- a2017 -->
<g id="node6" class="node">
<title>a2017</title>
<polygon fill="none" stroke="black" points="1444,-52 1062,-52 1062,-16 1444,-16 1444,-52"/>
<text text-anchor="middle" x="1253" y="-30.3" font-family="Times,serif" font-size="14.00">[2017] Deep Recurrent Q&#45;Learning for Partially Observable MDPs</text>
</g>
<!-- a2013&#45;&gt;a2017 -->
<g id="edge5" class="edge">
<title>a2013&#45;&gt;a2017</title>
<path fill="none" stroke="darkgreen" stroke-dasharray="5,2" d="M935.88,-88.99C998.21,-78.38 1078.5,-64.71 1142.69,-53.78"/>
<polygon fill="darkgreen" stroke="darkgreen" points="1143.58,-57.18 1152.85,-52.05 1142.4,-50.28 1143.58,-57.18"/>
</g>
<!-- b2017 -->
<g id="node7" class="node">
<title>b2017</title>
<polygon fill="none" stroke="black" points="1903.5,-52 1462.5,-52 1462.5,-16 1903.5,-16 1903.5,-52"/>
<text text-anchor="middle" x="1683" y="-30.3" font-family="Times,serif" font-size="14.00">[2017] Rainbow: Combining Improvements in Deep Reinforcement Learning</text>
</g>
<!-- a2013&#45;&gt;b2017 -->
<g id="edge6" class="edge">
<title>a2013&#45;&gt;b2017</title>
<path fill="none" stroke="darkgreen" stroke-dasharray="5,2" d="M999.06,-92.33C1133.08,-81.1 1323.98,-65.09 1470.06,-52.85"/>
<polygon fill="darkgreen" stroke="darkgreen" points="1470.38,-56.34 1480.05,-52.01 1469.8,-49.36 1470.38,-56.34"/>
</g>
</g>
</svg>
