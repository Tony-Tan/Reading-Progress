digraph ML_Math{           //设置分辨率

	{
		node[shape=box]
		
		//1993
		a1993[label="[1993] Reinforcement Learning for Robots Using Neural Networks"];
		//1994
		a1994[label="[1994]Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems"]
		//1995
		a1995[label="[1995] Simple statistical gradient-following algorithms for connectionist reinforcement learning"]
		//1999
		a1999[label="[1999] Policy Gradient Methods for Reinforcement Learning with Function Approximation"]
		//2001
		a2001[label="[2001]A Natural Policy Gradient"]
		//2013
		a2013[label="[2013] Playing Atari with Deep Reinforcement Learning"];
		//2015
		a2015[label="[2015] Deep Reinforcement Learning with Double Q-learning"]
		//2016
		a2016[label="[2016] Prioritized Experience Replay"]
		b2016[label="[2016] Dueling Network Architectures for Deep Reinforcement Learning"]
		c2016[label="[2016] Asynchronous Methods for Deep Reinforcement Learning"]
		//2017
		a2017[label="[2017] Deep Recurrent Q-Learning for Partially Observable MDPs"]
		b2017[label="[2017] Rainbow: Combining Improvements in Deep Reinforcement Learning"]
		c2017[label="[2017] Trust Region Policy Optimization"]
		d2017[label="[2017] Emergence of Locomotion Behaviours in Rich Environments"]
		e2017[label="[2017] Proximal Policy Optimization Algorithms"]
	}


	{
		edge[color=darkgreen,style=dashed]
		a1993->a2013[label="experience replay mechanism"];
		a2013->a2015;
		a2013->a2016;
		a2013->b2016;
		a2013->a2017;
		a2013->b2017;
		c2016->c2017;
		c2017->d2017;
		c2017->e2017
		a2013->c2016;
		a1999->e2017;
		a1999->c2017;
		e2017->d2017;
		a2001->c2017;
		a1999->a2001;
		a1995->a1999;
		a1994->a1999;
	}
	subgraph cluster_dqn{
		label="DQN"
		style="dashed"
		node [shape = box, color = blue]
		a2013; a2015; a2016; b2016; b2017;a2017;
	}
	subgraph cluster_pg{
		label="Policy Gradient"
		style="dashed"
		node [shape = box, color = blue]
		c2016;d2017;c2017;e2017;a1999;a2001;a1995;a1994;
	}
	
}